{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cadb89fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 15:22:04.792799: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-29 15:22:04.942118: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-29 15:22:06.877997: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b888b85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "success_df = pd.read_pickle(\"merged.df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f353dad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_genotypes = ['WT', 'wt', 'Wt', 'wild type', 'control', 'KO',\n",
    "                    'wild-type', 'wildtype', 'Control', 'Wild type', \n",
    "                    'Wild-type', 'Wildtype', 'Wild Type', 'knockout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54920746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define the BIO labels\n",
    "BIO_LABELS = ['B-GENOTYPE', 'I-GENOTYPE', 'O']\n",
    "\n",
    "\n",
    "def split_list(lst, size):\n",
    "    return [lst[i:i+size] for i in range(0, len(lst), size)]\n",
    "\n",
    "# Tokenize the text and do BIO labeling\n",
    "tokens = []\n",
    "labels = []\n",
    "token_label_pairs = []\n",
    "for i, row in success_df.iterrows():\n",
    "    text = row['Description']\n",
    "    genotype = row['genotype']\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    token_labels = ['O'] * len(tokenized_text)\n",
    "    for g in genotype:\n",
    "        if g not in ignore_genotypes:\n",
    "            g_tokens = tokenizer.tokenize(g)\n",
    "            start_idx = 0\n",
    "            for j, token in enumerate(tokenized_text):\n",
    "                if token == g_tokens[start_idx]:\n",
    "                    if start_idx == len(g_tokens) - 1:\n",
    "                        token_labels[j] = BIO_LABELS[0]\n",
    "                    else:\n",
    "                        token_labels[j] = BIO_LABELS[0]\n",
    "                        start_idx += 1\n",
    "                        while start_idx < len(g_tokens) and tokenized_text[j+1] == g_tokens[start_idx]:\n",
    "                            token_labels[j+1] = BIO_LABELS[1]\n",
    "                            j += 1\n",
    "                            start_idx += 1\n",
    "                        if start_idx == len(g_tokens):\n",
    "                            break\n",
    "    token_chunks = split_list(tokenized_text, 500)\n",
    "    tokens.extend(token_chunks)\n",
    "    label_chunks = split_list(token_labels, 500)\n",
    "    labels.extend(label_chunks)\n",
    "    token_label_pairs.extend([[(a, b) for a, b in zip(sublist_A, sublist_B)] for sublist_A, sublist_B in zip(token_chunks, label_chunks)])\n",
    "\n",
    "# Create a new dataframe with tokenized text and BIO labels\n",
    "new_df = pd.DataFrame({'tokens': tokens, 'labels': labels, 'token_label_pairs': token_label_pairs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a700ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('eco', 'O'),\n",
       " ('##tro', 'O'),\n",
       " ('##pic', 'O'),\n",
       " ('viral', 'O'),\n",
       " ('integration', 'O'),\n",
       " ('site', 'O'),\n",
       " ('1', 'O'),\n",
       " ('(', 'O'),\n",
       " ('ev', 'B-GENOTYPE'),\n",
       " ('##i', 'I-GENOTYPE'),\n",
       " ('##1', 'I-GENOTYPE'),\n",
       " ('/', 'O'),\n",
       " ('me', 'O'),\n",
       " ('##com', 'O'),\n",
       " (')', 'O'),\n",
       " ('over', 'B-GENOTYPE'),\n",
       " ('##ex', 'I-GENOTYPE'),\n",
       " ('##press', 'O'),\n",
       " ('##ion', 'O'),\n",
       " ('is', 'O'),\n",
       " ('common', 'O'),\n",
       " ('in', 'O'),\n",
       " ('my', 'O'),\n",
       " ('##elo', 'O'),\n",
       " ('##id', 'O'),\n",
       " ('mali', 'O'),\n",
       " ('##gnan', 'O'),\n",
       " ('##cies', 'O'),\n",
       " ('.', 'O'),\n",
       " ('we', 'O'),\n",
       " ('present', 'O'),\n",
       " ('a', 'O'),\n",
       " ('new', 'O'),\n",
       " ('ev', 'O'),\n",
       " ('##i', 'O'),\n",
       " ('##1', 'O'),\n",
       " ('trans', 'O'),\n",
       " ('##genic', 'O'),\n",
       " ('mouse', 'O'),\n",
       " ('model', 'O'),\n",
       " ('with', 'O'),\n",
       " ('ind', 'O'),\n",
       " ('##ucible', 'O'),\n",
       " ('expression', 'O'),\n",
       " ('in', 'O'),\n",
       " ('hem', 'O'),\n",
       " ('##ato', 'O'),\n",
       " ('##po', 'O'),\n",
       " ('##ie', 'O'),\n",
       " ('##tic', 'O'),\n",
       " ('stem', 'O'),\n",
       " ('cells', 'O'),\n",
       " ('(', 'O'),\n",
       " ('hs', 'O'),\n",
       " ('##cs', 'O'),\n",
       " (')', 'O'),\n",
       " ('and', 'O'),\n",
       " ('pro', 'O'),\n",
       " ('##gen', 'O'),\n",
       " ('##itor', 'O'),\n",
       " ('cells', 'O'),\n",
       " ('(', 'O'),\n",
       " ('hp', 'O'),\n",
       " ('##cs', 'O'),\n",
       " (')', 'O'),\n",
       " ('at', 'O'),\n",
       " ('lower', 'O'),\n",
       " ('levels', 'O'),\n",
       " ('.', 'O'),\n",
       " ('upon', 'O'),\n",
       " ('ex', 'O'),\n",
       " ('##ogen', 'O'),\n",
       " ('##ous', 'O'),\n",
       " ('ev', 'O'),\n",
       " ('##i', 'O'),\n",
       " ('##1', 'O'),\n",
       " ('induction', 'O'),\n",
       " (',', 'O'),\n",
       " ('mice', 'O'),\n",
       " ('displayed', 'O'),\n",
       " ('an', 'O'),\n",
       " ('##emia', 'O'),\n",
       " (',', 'O'),\n",
       " ('th', 'O'),\n",
       " ('##rom', 'O'),\n",
       " ('##bo', 'O'),\n",
       " ('##cy', 'O'),\n",
       " ('##top', 'O'),\n",
       " ('##enia', 'O'),\n",
       " (',', 'O'),\n",
       " ('l', 'O'),\n",
       " ('##ym', 'O'),\n",
       " ('##ph', 'O'),\n",
       " ('##open', 'O'),\n",
       " ('##ia', 'O'),\n",
       " (',', 'O'),\n",
       " ('and', 'O'),\n",
       " ('d', 'O'),\n",
       " ('##ys', 'O'),\n",
       " ('##pl', 'O'),\n",
       " ('##asia', 'O'),\n",
       " ('in', 'O'),\n",
       " ('er', 'O'),\n",
       " ('##yt', 'O'),\n",
       " ('##hr', 'O'),\n",
       " ('##oid', 'O'),\n",
       " ('and', 'O'),\n",
       " ('mega', 'O'),\n",
       " ('##kar', 'O'),\n",
       " ('##yo', 'O'),\n",
       " ('##cy', 'O'),\n",
       " ('##te', 'O'),\n",
       " ('cells', 'O'),\n",
       " ('with', 'O'),\n",
       " ('a', 'O'),\n",
       " ('significant', 'O'),\n",
       " ('expansion', 'O'),\n",
       " ('of', 'O'),\n",
       " ('committed', 'O'),\n",
       " ('my', 'O'),\n",
       " ('##elo', 'O'),\n",
       " ('##id', 'O'),\n",
       " ('pro', 'O'),\n",
       " ('##gen', 'O'),\n",
       " ('##itor', 'O'),\n",
       " ('cells', 'O'),\n",
       " (',', 'O'),\n",
       " ('resembling', 'O'),\n",
       " ('human', 'O'),\n",
       " ('my', 'O'),\n",
       " ('##elo', 'O'),\n",
       " ('##dy', 'O'),\n",
       " ('##sp', 'O'),\n",
       " ('##lastic', 'O'),\n",
       " ('syndrome', 'O'),\n",
       " ('/', 'O'),\n",
       " ('my', 'O'),\n",
       " ('##elo', 'O'),\n",
       " ('##pro', 'O'),\n",
       " ('##life', 'O'),\n",
       " ('##rative', 'O'),\n",
       " ('neo', 'O'),\n",
       " ('##pl', 'O'),\n",
       " ('##as', 'O'),\n",
       " ('##m', 'O'),\n",
       " ('(', 'O'),\n",
       " ('md', 'O'),\n",
       " ('##s', 'O'),\n",
       " ('/', 'O'),\n",
       " ('mp', 'O'),\n",
       " ('##n', 'O'),\n",
       " (')', 'O'),\n",
       " ('-', 'O'),\n",
       " ('like', 'O'),\n",
       " ('disease', 'O'),\n",
       " ('.', 'O'),\n",
       " ('methods', 'O'),\n",
       " (':', 'O'),\n",
       " ('lin', 'O'),\n",
       " ('-', 'O'),\n",
       " ('c', 'O'),\n",
       " ('-', 'O'),\n",
       " ('kit', 'O'),\n",
       " ('+', 'O'),\n",
       " ('cells', 'O'),\n",
       " ('were', 'O'),\n",
       " ('isolated', 'O'),\n",
       " ('from', 'O'),\n",
       " ('3', 'O'),\n",
       " ('pairs', 'O'),\n",
       " ('of', 'O'),\n",
       " ('w', 'O'),\n",
       " ('##t', 'O'),\n",
       " ('and', 'O'),\n",
       " ('ev', 'O'),\n",
       " ('##i', 'O'),\n",
       " ('##1', 'O'),\n",
       " ('over', 'O'),\n",
       " ('##ex', 'O'),\n",
       " ('##pressing', 'B-GENOTYPE'),\n",
       " ('mice', 'O'),\n",
       " ('.', 'O'),\n",
       " ('around', 'O'),\n",
       " ('1', 'O'),\n",
       " ('##x', 'O'),\n",
       " ('##10', 'O'),\n",
       " ('##6', 'O'),\n",
       " ('lin', 'O'),\n",
       " ('-', 'O'),\n",
       " ('c', 'O'),\n",
       " ('-', 'O'),\n",
       " ('kit', 'O'),\n",
       " ('+', 'O'),\n",
       " ('cells', 'O'),\n",
       " ('were', 'O'),\n",
       " ('harvested', 'O'),\n",
       " ('from', 'O'),\n",
       " ('each', 'O'),\n",
       " ('mouse', 'O'),\n",
       " ('.', 'O'),\n",
       " ('then', 'O'),\n",
       " ('the', 'O'),\n",
       " ('cells', 'O'),\n",
       " ('were', 'O'),\n",
       " ('l', 'O'),\n",
       " ('##ys', 'O'),\n",
       " ('##ated', 'O'),\n",
       " ('by', 'O'),\n",
       " ('tri', 'O'),\n",
       " ('##zo', 'O'),\n",
       " ('##l', 'O'),\n",
       " ('and', 'O'),\n",
       " ('total', 'O'),\n",
       " ('rna', 'O'),\n",
       " ('was', 'O'),\n",
       " ('extracted', 'O'),\n",
       " ('by', 'O'),\n",
       " ('ph', 'O'),\n",
       " ('##eno', 'O'),\n",
       " ('##l', 'O'),\n",
       " ('-', 'O'),\n",
       " ('ch', 'O'),\n",
       " ('##lor', 'O'),\n",
       " ('##of', 'O'),\n",
       " ('##or', 'O'),\n",
       " ('##m', 'O'),\n",
       " ('.', 'O'),\n",
       " ('results', 'O'),\n",
       " (':', 'O'),\n",
       " ('molecular', 'O'),\n",
       " ('pathways', 'O'),\n",
       " ('altered', 'O'),\n",
       " ('in', 'O'),\n",
       " ('lin', 'O'),\n",
       " ('-', 'O'),\n",
       " ('c', 'O'),\n",
       " ('-', 'O'),\n",
       " ('kit', 'O'),\n",
       " ('+', 'O'),\n",
       " ('cells', 'O'),\n",
       " ('from', 'O'),\n",
       " ('ev', 'O'),\n",
       " ('##i', 'O'),\n",
       " ('##1', 'O'),\n",
       " ('-', 'O'),\n",
       " ('o', 'O'),\n",
       " ('##e', 'O'),\n",
       " ('mice', 'O'),\n",
       " ('.', 'O'),\n",
       " ('conclusions', 'O'),\n",
       " (':', 'O'),\n",
       " ('multiple', 'O'),\n",
       " ('molecular', 'O'),\n",
       " ('pathways', 'O'),\n",
       " ('changed', 'O'),\n",
       " ('in', 'O'),\n",
       " ('ev', 'O'),\n",
       " ('##i', 'O'),\n",
       " ('##1', 'O'),\n",
       " ('over', 'O'),\n",
       " ('##ex', 'O'),\n",
       " ('##pressing', 'B-GENOTYPE'),\n",
       " ('hem', 'O'),\n",
       " ('##ato', 'O'),\n",
       " ('##po', 'O'),\n",
       " ('##ie', 'O'),\n",
       " ('##tic', 'O'),\n",
       " ('stem', 'O'),\n",
       " ('and', 'O'),\n",
       " ('pro', 'O'),\n",
       " ('##gen', 'O'),\n",
       " ('##itor', 'O'),\n",
       " ('cells', 'O'),\n",
       " ('.', 'O'),\n",
       " ('overall', 'O'),\n",
       " ('design', 'O'),\n",
       " (':', 'O'),\n",
       " ('3', 'O'),\n",
       " ('pairs', 'O'),\n",
       " ('of', 'O'),\n",
       " ('w', 'O'),\n",
       " ('##t', 'O'),\n",
       " ('and', 'O'),\n",
       " ('ev', 'O'),\n",
       " ('##i', 'O'),\n",
       " ('##1', 'O'),\n",
       " ('over', 'O'),\n",
       " ('##ex', 'O'),\n",
       " ('##pressing', 'B-GENOTYPE'),\n",
       " ('mice', 'O'),\n",
       " ('at', 'O'),\n",
       " ('the', 'O'),\n",
       " ('same', 'O'),\n",
       " ('age', 'O'),\n",
       " ('and', 'O'),\n",
       " ('gender', 'O'),\n",
       " ('were', 'O'),\n",
       " ('sacrificed', 'O'),\n",
       " ('and', 'O'),\n",
       " ('the', 'O'),\n",
       " ('b', 'O'),\n",
       " ('##m', 'O'),\n",
       " ('cells', 'O'),\n",
       " ('were', 'O'),\n",
       " ('harvested', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.iloc[2].token_label_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2be0bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['WT', 'Evi1 overexpressing'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_df.iloc[2].genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43427c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_pickle(\"tokens.df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28fc8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
